Let me tell you about our project first.
We’ve finished three big features, the API, the Total migration Tool and the incremental migration
For API, we need the best request performance, so to get the data from redis directly without any calculation or integration would be a good choice. Thus, I store the processed data so that API can access the result directly without any calculation. To make this work,  I took the related calculation, like removing duplicated data, ahead on the migration project. 
Take the org id 541000 as instance, there are 4,727 documents and the values of their identifiers contains 541000, besides each documents has more than 7 identifiers. That means this org id has more than 30, 000 related identifiers and unfortunately most of them are duplicated. So I need to remove these duplicated data and save the final key-value what I want in Redis.
Due to this reason, I didn’t save any reference id, such as doc id. If we take the reference id as our solution, the process is that when an api request, we should get more than 4,000 reference id firstly and loop them to get each identifiers, lastly we also need to deduplicated these data. And this calculation will occur in API request and make our response slowly.
Then back to the question of Oplog that why I need to do the comparison. The oplog data only has the new status and the reference id that we change. For example, one of the document of 541000 org id. This document has 7 identifiers, one value of its identifier is ‘a’. so we also has a key ‘a’ in Redis, right? then we change this value to b.  we need to delete the key ‘a’ and add the new key ‘b’ in Reids. Here comes the question, if oplog doesn’t contain the ‘a’ log, and MongoDB also has changed to ‘b’, how should I know to delete the key ‘a’ in Redis? This issue is also occur even though we store reference id in Redis.
So, when we do baseline, we need a log or a backup so that we can track what it changes.
What do you think? Or do you have any other better suggestion?
